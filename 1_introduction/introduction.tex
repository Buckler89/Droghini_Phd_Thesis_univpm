\chapter{Introduction}\label{ch:intro}

Outline, obiettivi, controbuti

The decreasing birth rate \cite{eurostat} and the contemporary increase of the life expectancy at birth \cite{Carone2006} in the majority of industrialized countries have been generating new challenges in the assistance of the elderly. The scientific community, companies and governments are trying to face them by investing in the development of efficient healthcare systems and solutions. The direction taken goes towards the development of smart home capable of taking care of the inhabitants by supporting and monitoring them in their daily actions \cite{Dawadi20161188, Principi2015a}. Since falls are one of the main cause of death for the elderly \cite{mubashir2013survey}, several efforts have been devoted to the development of algorithms for automatically detecting these events.





\section{Fall Detection Systems}
The continuous and unprecedented growth rate of the elderly world population is one of the primary aspects of concern for society and governments. Nowadays about 8.5\% of people in the world are more than 65 years old \cite{dhhsOlderPop,Carone2006}. Although the average life of the world population is getting longer, elderly people may not    necessarily live a healthier life. It is enough to say that 37.5 million falls require medical interventions and more than 600 thousand are cause of death every year worldwide. In particular, the population segment most affected by this problem is composed of elderly over 65 years that, with the growing mobility of the population, are more frequently left alone in their homes without aid in the case of need. Moreover, since falls are the leading cause of death and hospitalizations for older adults, this phenomenon leads to a substantial increase in the cost of healthcare \cite{whoFall, mubashir2013survey}. 
It is not surprising, thus, that the research community is encouraged, even by governments, to find reliable and performing solutions to minimize the damage caused by the human falls problem. This is also confirmed by the presence in the literature of several reviews dedicated to this specific topic \cite{mubashir2013survey, khan2017review, lapierre2017state, pannurat2014automatic, xu2018new, el2013fall}.
In fact, in the past few years, a variety of systems have been presented. One way to divide the methodologies for approaching the falls detection problem is based on the placement of the sensing devices \cite{mubashir2013survey}. The main categories are wearable, vision and environmental, with each category presenting their own advantages and disadvantages. Wearable systems do not suffer from ambient condition, but people may forget to wear them and they are not operational during the charging time, thus, some people may consider them annoying. Furthermore, a device must be installed on each person to be monitored. An environmental sensor may be used to avoid this kind of problems, but with other limitations. Vision systems, although they are actually environmental sensors, deserve a dedicated category because of many systems proposed in the literature based on this type of sensors \cite{mubashir2013survey}. This category includes several types of sensors like, e.g., cameras for which the major limitations are field-of-view constraints, lighting condition, positioning of multiple cameras and lack of privacy.
The ambient category includes several types of sensors. For example, radar doppler based systems used in \cite{wu2015radar} raise fewer privacy concerns, but they suffer from reflection and blind spots. In particular, for a data-driven system, another aspect that should not be underestimated is the need for a re-training when changing the environment to be monitored or even just some of its components such as the arrangement of furniture as happens in \cite{liu2008vision}.
All this implies that there is no optimal choice, which is instead, a compromise that depends on the type of environment that is monitored as well as on personal sensitivity of the subjects under monitoring.
Going into more detail, another significant distinction between falls detection systems can be made based on the type and amount of data used for the algorithm development \cite{khan2017review}. In fact, the problem can be approached either as supervised or unsupervised based on the availability of data in the hands of the researchers as well as their goals. 
Most state-of-the-art works tackle the problem under fully supervised conditions assuming they have enough data for falls. Almost all of these falls are simulated with professional mannequins \cite{werner2011fall, zigel2009method}  or by people with adequate protections \cite{li2012microphone, popescu2008acoustic} that however may not correctly emulate an actual fall. Although this approach leads to more accurate results, there is no guarantee that it will generalize well in real situations. 
Other researchers opt for approaches based on outlier/anomaly detection \cite{khan2015unsupervised, zhang2009detecting, popescu2009acoustic} because of the plentiful availability of data that can represent normal activity. However, it is challenging to define what ``normal activities'' are for such approaches, and the risk is to raise several false alarms. % come succede a noi con la ocsvm.
Perhaps the situation that most closely approximates reality is a hybrid between the previous ones, in which a large amount of data representing the normality are easily available, with just a few samples of real human fall (\textit{RHF}) and eventually some related synthetic or simulated data. In these situations, supervised approaches that suffer from strong data imbalance have to apply subsampling \cite{stone2015fall} or weighting \cite{khan2017review} techniques to mitigate this effect. Thus, the need to find an effective way to exploit the few available falls data is evident.


\section{State-Of-The-Art} 
\label{sec:soa}
Review dei sistemi per la fall detection basati sui vari tipi di sensori
accelerometers, vision, ambient. Per gli ambient paricolare enfasi sugli approcci basati su aduio.

As aforementioned, fall detection approaches can be divided based on their sensing technology, in particular if they employ wearable or ambient sensors. Regarding the first ones, the most common choice is to employ accelerometers. The algorithms proposed in \cite{Bourke2007} and \cite{Charlon2013} detect a fall by verifying if the acceleration signals exceed a certain threshold. In contrast, in \cite{Ozdemir2014} the authors implemented several machine learning techniques and studied their classification performance. For the experiments, a fall events dataset has been developed using six sensor units with three-axis accelerometers and worn by 14 persons who simulated falls from different angles. The best performing classifier resulted the $k$-Nearest Neighbour classifier. \cite{Lustrek2015} employed radio tags worn on the user's chest, waist, and ankles, and an optional three-axial accelerometer worn on the chest. The algorithms performs a basic activity recognition, distinguishing from walking, standing, sitting, sitting on the ground, lying down, the process of sitting or lying down, the process of standing up, and falling. The actual fall is detected combining the results of two classifiers, an SVM and a decision tree, and hand-crafted rules. The authors performed the experiments on a laboratory scenario and reported accuracies of 100\% combining radio tags and the accelerometer.

%\cite{lai2011detection}

Differently from wearable sensors, the physical quantities captured by ambient sensors are more heterogeneous. Generally, fall detectors are based on vibration, video or acoustic sensors, sometimes in combination with presence detectors.  In \cite{alwan2006smart} the fall detector is based on a floor vibration sensor and the algorithm detects a fall when the vibration pattern matches the one of a human fall. The authors do not give further details on the algorithm and report 100\% sensitivity and specificity on tests conducted on a dummy falls dataset. Yazar and colleagues \cite{Yazar2013} employ both passive infrared (PIR) sensors and floor vibration sensors. PIRs are employed to reduce false alarms, i.e., by detecting if a person is present in the region of interest. Single-tree complex wavelet transform features are extracted from the vibration signal and classified as fall or non-fall. In their dataset, the non-fall classes are represented by human (walking or running and sitting) or non-human activities (door slamming and a book falling). Three different classifiers have been compared: Euclidean distance, Mahalanobis distance and SVM, with the latter resulting in the most performing one, since it is able to classify human falls without errors regardless the employment of PIR sensors.

Regarding approaches based on audio signals, a common solution is to install several microphones in the building, usually on the ceiling or near the walls. Indeed, also single-microphone approaches exist but they are much less robust to environmental noise, thus resulting in poor performance. For example, in \cite{zhuang2009acoustic}, the authors employ a single far field microphone and they model audio segments by means of perceptual linear predictive (PLP) coefficients and GMM supervectors. An SVM with a kernel based on the Kullback-Leibler divergence, then, classifies the segment as being a fall or noise. For this purpose, nine classes of noise have been considered. In the experiments, the algorithm achieves an F$_1$-Measure of 67\% in the classification task, and an accuracy equal to 64\% in the detection task. 

The difficulty in using a single microphone drove the scientific community to employ multi-channel algorithms. In \cite{khan2015unsupervised} the authors present an unsupervised algorithm based on two microphones. The algorithm comprises a source separation and localization block to reduce the impact of background noise. Then, a one class Support Vector Machine is trained on MFCCs of non-fall events only. The SVM is then applied to distinguish normal sound events (i.e., sounds originating from normal activities) from abnormal ones (i.e., falls sounds). The authors validated the algorithm using simulated falls of persons only in presence of a television that produced the interfering sound. The results in terms of Area Under Curve are 0.9928 without interference and 0.9738 with 75\% interference. The work by Li and colleagues \cite{li2012microphone} employs a circular microphone array to firstly determine the position of the sound source, and then to enhance the signal by applying a beamformer. The height of the sound source is used as first filter to discriminate falls from non falls. If the sound originates from a source positioned on the ground, MFCC features are extracted and a $k$-Nearest Neighbour classifier is employed to detect persons' falls. The algorithm has been tested on a dataset composed of 120 simulated fall sounds and 120 non-fall sounds recorded in different acoustic conditions. In presence of background noise and TV interference, the resulting AUC was equal to 0.989 (accuracy 95\%) on clean conditions and 0.932 at 10\,dB SNR (accuracy 89\%). 

An approach to improve the performance of fall detection systems is to combine the information coming from different sensors. The approach proposed by Zigel \textit{et al.} \cite{zigel2009method} is based on a combination of sound and vibration sensors attached to the floor with a adhesive tape. The algorithm employs energy features extracted from the vibration signal to detect the fall event. Then, the event is classified as fall or non-fall with naive Bayes classifier employing features from both the vibration and sound signals. The experiments were conducted on a dataset containing falls of the ``Rescue Randy'' human mimicking doll and four objects, and the resulting sensitivity and specificity were respectively 97.5\% and 98.6\%. \cite{Liu2014} fuse the information coming from a Doppler sensor and motion sensors and classify falls with an SVM. The authors report an AUC equal to 0.98 with Doppler sensor only, and a further reduction of false alarms by 63\% employing motion sensors information. Motion, sound and video signals are employed in \cite{Doukas2011}. Signals are captured both from environment sensors and from body sensors. A fall is detected by analysing sounds and motion information, while visual and motion behaviour indicates the severity of the fall. The work by Toreyin and colleagues \cite{Toreyin2008} combines PIRs, microphones and vibration sensors. Signals are processed to extract features in the wavelet domain and and HMM classifier is then employed to detect falls. The authors showed the using PIR signals 100\% accuracy can be obtained.

\subsection{Problem Statement}


