\chapter{Introduction}\label{ch:intro}


Ambient intelligance + computation audio processing + obiettivi, controbuti, Outline

 The origins of the Ambient Intelligence are rooted in the birth of domotics and Home Automation. In fact, the concept of home automation design was already being started in the 80s for residential buildings. the information revolution, microprocessors and telecommunication networks are the main elements that have allowed the development of domotics. At the same time, increasingly sophisticated automation processes in the manufacturing field are at the base of building automation and domotics applications, transferring the control and automation systems present in the factories, with appropriate measures, to the building and its plants. During the decade '70 '80 the foundations for the transformation of household appliances were laid. In this phase, we witness the first transition from the electric house to the electronic house; subsequently, the progress of the sector will lead to the current concepts of integrated home system, and therefore bringing with it the concept of services that put man at the centre, and therefore of \textit{ambient intelligence}. The vision of the Ambient Intelligence (AmI) \cite{ducatel2001scenarios} has its foundations in the article M. Weiser \cite{weiser1991}. He states that ``the deepest technologies are those that disappear'' and states that computer technology at the time of its maturity should be invisible.
 Today the efforts in this direction are aimed at creating a ``non-deterministic and open'' cyberspace within which autonomous and intelligent entities will interact in order to put man at the centre of a design that will see the realisation of the fully integrated home of the future. This space will be able to self-organise and self-adapt to the user and anticipating his needs. The systems that conform to this vision will offer technological solutions that will be integrated into the environment, context-aware, tailored to the user need, able to adapt actions in new scenarios, able to anticipate the needs and wishes of users, all with minimal user intervention. 
 The objects and the environment will interact with each other in order to support users in carrying out their daily activities in a natural way, using the information and the intelligence that is hidden in the technological infrastructure that connects the devices (the technological complexity will become invisible for the user).
 In an AmI system, many heterogeneous devices work in cooperation to support users in everyday activities. As a result, the intelligence has been introduced in the domestic environment to provide more comfortable spaces for the inhabitants and allow the automatic implementation of different functions, such as ensuring greater independence and autonomy of the inhabitants acting in the areas of security/safety and issues of Ambient Assisted Living (AAL). A particular its application to the field of AAL is precisely the human fall detection. 
 
The decreasing birth rate \cite{eurostat} and the contemporary increase of the life expectancy at birth \cite{Carone2006} in the majority of industrialized countries have been generating new challenges in the assistance of the elderly. The scientific community, companies and governments are trying to face them by investing in the development of efficient healthcare systems and solutions. The direction taken goes towards the development of smart home capable of taking care of the inhabitants by supporting and monitoring them in their daily actions \cite{Dawadi20161188, Principi2015a}. Since falls are one of the main cause of death for the elderly \cite{mubashir2013survey}, several efforts have been devoted to the development of algorithms for automatically detecting these events.
This work is aimed at the presentation of different computational audio processing systems for fall detection. The approach described in each chapter follow a data available perspective. 

INSERIRE CONTRIBUTI E OBIETTIVI

The outline of the dissertation is the following.
\secref{sec:fds} introduce the human fall classification task with an update state of the art of the approaches mainly related to those that are audio based. \chref{ch:backg} gives an overview of the theoretical background of the data-driven techniques used in the presented approaches. The \chref{ch:dataset} described the dataset made by the authors, used for the assessment of the systems. \chref{ch:supervised_approaches} presents the supervised approaches aimed to evaluate both the created dataset and the proposed innovative sensor.
The unsupervised system are described in \chref{ch:unsupervised_approaches} where no human fall data has been used to train the algorithms.
In \chref{ch:weakley_supervised} approaches that operate in more realistic conditions are described.





\section{Fall Detection Systems}
\label{sec:fds}
The continuous and unprecedented growth rate of the elderly world population is one of the primary aspects of concern for society and governments. Nowadays about 8.5\% of people in the world are more than 65 years old \cite{dhhsOlderPop,Carone2006}. Although the average life of the world population is getting longer, elderly people may not    necessarily live a healthier life. It is enough to say that 37.5 million falls require medical interventions and more than 600 thousand are cause of death every year worldwide. In particular, the population segment most affected by this problem is composed of elderly over 65 years that, with the growing mobility of the population, are more frequently left alone in their homes without aid in the case of need. Moreover, since falls are the leading cause of death and hospitalizations for older adults, this phenomenon leads to a substantial increase in the cost of healthcare \cite{whoFall, mubashir2013survey}. 
It is not surprising, thus, that the research community is encouraged, even by governments, to find reliable and performing solutions to minimize the damage caused by the human falls problem. This is also confirmed by the presence in the literature of several reviews dedicated to this specific topic \cite{mubashir2013survey, khan2017review, lapierre2017state, pannurat2014automatic, xu2018new, el2013fall}.
In fact, in the past few years, a variety of systems have been presented. One way to divide the methodologies for approaching the falls detection problem is based on the placement of the sensing devices \cite{mubashir2013survey}. The main categories are wearable, vision and environmental, with each category presenting their own advantages and disadvantages. Wearable systems do not suffer from ambient condition, but people may forget to wear them and they are not operational during the charging time, thus, some people may consider them annoying. Furthermore, a device must be installed on each person to be monitored. An environmental sensor may be used to avoid this kind of problems, but with other limitations. Vision systems, although they are actually environmental sensors, deserve a dedicated category because of many systems proposed in the literature based on this type of sensors \cite{mubashir2013survey}. This category includes several types of sensors like, e.g., cameras for which the major limitations are field-of-view constraints, lighting condition, positioning of multiple cameras and lack of privacy.
The ambient category includes several types of sensors. For example, radar doppler based systems used in \cite{wu2015radar} raise fewer privacy concerns, but they suffer from reflection and blind spots. In particular, for a data-driven system, another aspect that should not be underestimated is the need for a re-training when changing the environment to be monitored or even just some of its components such as the arrangement of furniture as happens in \cite{liu2008vision}.
All this implies that there is no optimal choice, which is instead, a compromise that depends on the type of environment that is monitored as well as on personal sensitivity of the subjects under monitoring.
Going into more detail, another significant distinction between falls detection systems can be made based on the type and amount of data used for the algorithm development \cite{khan2017review}. In fact, the problem can be approached either as supervised or unsupervised based on the availability of data in the hands of the researchers as well as their goals. 
Most state-of-the-art works tackle the problem under fully supervised conditions assuming they have enough data for falls. Almost all of these falls are simulated with professional mannequins \cite{werner2011fall, zigel2009method}  or by people with adequate protections \cite{li2012microphone, popescu2008acoustic} that however may not correctly emulate an actual fall. Although this approach leads to more accurate results, there is no guarantee that it will generalize well in real situations. 
Other researchers opt for approaches based on outlier/anomaly detection \cite{khan2015unsupervised, zhang2009detecting, popescu2009acoustic} because of the plentiful availability of data that can represent normal activity. However, it is challenging to define what ``normal activities'' are for such approaches, and the risk is to raise several false alarms. % come succede a noi con la ocsvm.
Perhaps the situation that most closely approximates reality is a hybrid between the previous ones, in which a large amount of data representing the normality are easily available, with just a few samples of real human fall (\textit{RHF}) and eventually some related synthetic or simulated data. In these situations, supervised approaches that suffer from strong data imbalance have to apply subsampling \cite{stone2015fall} or weighting \cite{khan2017review} techniques to mitigate this effect. Thus, the need to find an effective way to exploit the few available falls data is evident.

\section{State-Of-The-Art} 
\label{sec:soa}
Review dei sistemi per la fall detection basati sui vari tipi di sensori
accelerometers, vision, ambient. Per gli ambient paricolare enfasi sugli approcci basati su aduio.

As aforementioned, fall detection approaches can be divided based on their sensing technology, in particular if they employ wearable or ambient sensors. Regarding the first ones, the most common choice is to employ accelerometers. The algorithms proposed in \cite{Bourke2007} and \cite{Charlon2013} detect a fall by verifying if the acceleration signals exceed a certain threshold. In contrast, in \cite{Ozdemir2014} the authors implemented several machine learning techniques and studied their classification performance. For the experiments, a fall events dataset has been developed using six sensor units with three-axis accelerometers and worn by 14 persons who simulated falls from different angles. The best performing classifier resulted the $k$-Nearest Neighbour classifier. \cite{Lustrek2015} employed radio tags worn on the user's chest, waist, and ankles, and an optional three-axial accelerometer worn on the chest. The algorithms performs a basic activity recognition, distinguishing from walking, standing, sitting, sitting on the ground, lying down, the process of sitting or lying down, the process of standing up, and falling. The actual fall is detected combining the results of two classifiers, an SVM and a decision tree, and hand-crafted rules. The authors performed the experiments on a laboratory scenario and reported accuracies of 100\% combining radio tags and the accelerometer.

%\cite{lai2011detection}

Differently from wearable sensors, the physical quantities captured by ambient sensors are more heterogeneous. Generally, fall detectors are based on vibration, video or acoustic sensors, sometimes in combination with presence detectors.  In \cite{alwan2006smart} the fall detector is based on a floor vibration sensor and the algorithm detects a fall when the vibration pattern matches the one of a human fall. The authors do not give further details on the algorithm and report 100\% sensitivity and specificity on tests conducted on a dummy falls dataset. Yazar and colleagues \cite{Yazar2013} employ both passive infrared (PIR) sensors and floor vibration sensors. PIRs are employed to reduce false alarms, i.e., by detecting if a person is present in the region of interest. Single-tree complex wavelet transform features are extracted from the vibration signal and classified as fall or non-fall. In their dataset, the non-fall classes are represented by human (walking or running and sitting) or non-human activities (door slamming and a book falling). Three different classifiers have been compared: Euclidean distance, Mahalanobis distance and SVM, with the latter resulting in the most performing one, since it is able to classify human falls without errors regardless the employment of PIR sensors.

Regarding approaches based on audio signals, a common solution is to install several microphones in the building, usually on the ceiling or near the walls. Indeed, also single-microphone approaches exist but they are much less robust to environmental noise, thus resulting in poor performance. For example, in \cite{zhuang2009acoustic}, the authors employ a single far field microphone and they model audio segments by means of perceptual linear predictive (PLP) coefficients and GMM supervectors. An SVM with a kernel based on the Kullback-Leibler divergence, then, classifies the segment as being a fall or noise. For this purpose, nine classes of noise have been considered. In the experiments, the algorithm achieves an F$_1$-Measure of 67\% in the classification task, and an accuracy equal to 64\% in the detection task. 

The difficulty in using a single microphone drove the scientific community to employ multi-channel algorithms. In \cite{khan2015unsupervised} the authors present an unsupervised algorithm based on two microphones. The algorithm comprises a source separation and localization block to reduce the impact of background noise. Then, a one class Support Vector Machine is trained on MFCCs of non-fall events only. The SVM is then applied to distinguish normal sound events (i.e., sounds originating from normal activities) from abnormal ones (i.e., falls sounds). The authors validated the algorithm using simulated falls of persons only in presence of a television that produced the interfering sound. The results in terms of Area Under Curve are 0.9928 without interference and 0.9738 with 75\% interference. The work by Li and colleagues \cite{li2012microphone} employs a circular microphone array to firstly determine the position of the sound source, and then to enhance the signal by applying a beamformer. The height of the sound source is used as first filter to discriminate falls from non falls. If the sound originates from a source positioned on the ground, MFCC features are extracted and a $k$-Nearest Neighbour classifier is employed to detect persons' falls. The algorithm has been tested on a dataset composed of 120 simulated fall sounds and 120 non-fall sounds recorded in different acoustic conditions. In presence of background noise and TV interference, the resulting AUC was equal to 0.989 (accuracy 95\%) on clean conditions and 0.932 at 10\,dB SNR (accuracy 89\%). 

An approach to improve the performance of fall detection systems is to combine the information coming from different sensors. The approach proposed by Zigel \textit{et al.} \cite{zigel2009method} is based on a combination of sound and vibration sensors attached to the floor with a adhesive tape. The algorithm employs energy features extracted from the vibration signal to detect the fall event. Then, the event is classified as fall or non-fall with naive Bayes classifier employing features from both the vibration and sound signals. The experiments were conducted on a dataset containing falls of the ``Rescue Randy'' human mimicking doll and four objects, and the resulting sensitivity and specificity were respectively 97.5\% and 98.6\%. \cite{Liu2014} fuse the information coming from a Doppler sensor and motion sensors and classify falls with an SVM. The authors report an AUC equal to 0.98 with Doppler sensor only, and a further reduction of false alarms by 63\% employing motion sensors information. Motion, sound and video signals are employed in \cite{Doukas2011}. Signals are captured both from environment sensors and from body sensors. A fall is detected by analysing sounds and motion information, while visual and motion behaviour indicates the severity of the fall. The work by Toreyin and colleagues \cite{Toreyin2008} combines PIRs, microphones and vibration sensors. Signals are processed to extract features in the wavelet domain and and HMM classifier is then employed to detect falls. The authors showed the using PIR signals 100\% accuracy can be obtained.

\section{Case studies}
Generally speaking, the ``analytical methods'' distinguish between fall and non-fall events by applying a threshold directly on the acquired signals or on the features sequences extracted from them \cite{noury2007fall}.
These methods are generally built exploiting some a-priori knowledge to operate in a specific scenario and needs manual tuning of the hyperparameters of the algorithm. For these reasons, the ``analytical methods'' can hardly perform when the operating conditions and the subjects are variable. In ``machine learning'' methods, the algorithm learn from the data how to discriminate falls from non-falls \cite{noury2007fall}. Between them can be distinguished ``supervised'' and  ``unsupervised'' approaches. The fist  require a labelled dataset for training the classifier, while the latter build a normality model considering only the non-fall events. Regardless of the used approach, machine learning tasks require that the inputs are mathematically and computationally convenient to process, so researchers have traditionally relied on a two-stage strategy: some features are extracted from the raw signals of dataset and are then used as input for the successive tasks. The choice and design of the appropriate features requires considerable expertise about the problem and constitutes a significant engineering effort.

In this work, different application of computational audio processing based on machine learning techniques for ambient intelligence are analyzed. Particular attention was given to the condition of knowledge for each proposed approach. In fact, the presented works start from a total knowledge of the data describing first the supervised methods dedicated to the falls detection. Because of the difficulty in recovering examples of human fall for algorithm training, this is primarily just a case study. Subsequently, methods that operate in the opposite condition are described, that is, without the a priori knowledge of signals related to the human fall. This would be the ideal condition, but that does not present very high reliability in terms of false alarms rate. Finally, the problem is dealt with from a more realistic point of view, in which only a small portion of data related to the human fall is available, while a vast knowledge of what is not human fall can be accessed.

