\chapter{Introduction}\label{ch:intro}

The origins of Ambient Intelligence are rooted in the birth of domotics and Home Automation. In fact, the concept of home automation design was already being started in the 80s for residential buildings. Information revolution, microprocessors, and telecommunication networks are the main elements that have allowed the development of domotics. At the same time, increasingly sophisticated automation processes in the manufacturing field are at the base of building automation and domotics applications, transferring the control and automation systems present in the factories, with appropriate measures, to the building and its plants. During the decade '70 '80, the foundations for the transformation of household appliances were laid. In this phase, we witness the first transition from the electric house to the electronic house; subsequently, the progress of the sector will lead to the current concepts of the integrated home system, bringing with it the concept of services that put man at the center, and therefore of \textit{ambient intelligence}. The vision of the Ambient Intelligence (AmI) \cite{ducatel2001scenarios} has its foundations in the article by M. Weiser \cite{weiser1991}. He states that ``the deepest technologies are those that disappear'' and that computer technology at the time of its maturity should be invisible.
Today the efforts in this direction are aimed at creating a ``non-deterministic and open'' cyberspace within which autonomous and intelligent entities will interact in order to put man at the center of a design that will see the realization of the fully integrated home of the future. This space will be able to self-organize and self-adapt to the user and anticipating his needs. The systems that conform to this vision will offer technological solutions that will be integrated into the environment, context-aware, tailored to the user need, able to adapt actions in new scenarios and able to anticipate the needs and wishes of users, all with minimal user intervention. 
The objects and the environment will interact with each other in order to support users in carrying out their daily activities in a natural way, using the information and the intelligence that is hidden in the technological infrastructure that connects the devices (the technological complexity will become invisible for the user).
In an AmI system, many heterogeneous devices work in cooperation to support users in everyday activities. As a result, the intelligence has been introduced in the domestic environment to provide more comfortable spaces for the inhabitants and allow the automatic implementation of different functions, such as ensuring greater independence and autonomy of the inhabitants acting in the areas of security/safety and issues of Ambient Assisted Living (AAL). A particular application in the field of AAL is precisely the human fall detection. 
The decreasing birth rate \cite{eurostat} and the simultaneous increase of the life expectancy at birth \cite{Carone2006} in the majority of industrialized countries have been generating new challenges in the assistance of the elderly. The scientific community, companies, and governments are trying to face them by investing in the development of efficient healthcare systems and solutions. The direction taken goes towards the development of smart home capable of taking care of the inhabitants by supporting and monitoring them in their daily actions \cite{Dawadi20161188, Principi2015a}. Since falls are one of the leading cause of death for the elderly \cite{mubashir2013survey}, several efforts have been devoted to the development of algorithms for automatically detecting this kind of events.



\section{Fall Detection Systems}
\label{sec:fds}
The continuous and unprecedented growth rate of the elderly world population is one of the primary aspects of concern for society and governments. Nowadays about 8.5\% of people in the world are more than 65 years old \cite{dhhsOlderPop,Carone2006}. Although the average life of the world population is getting longer, older adults may not necessarily live a healthier life. It is enough to say that 37.5 million falls require medical interventions and more than 600 thousand are the cause of death every year worldwide. In particular, the population segment most affected by this problem is composed of elderly over 65 years that, with the growing mobility of the population, are more frequently left alone in their homes without aid in the case of need. Moreover, since falls are the leading cause of death and hospitalizations for older adults, this phenomenon leads to a substantial increase in the cost of healthcare \cite{whoFall, mubashir2013survey}. 
It is not surprising, thus, that the research community is encouraged, even by governments, to find reliable and performing solutions to minimize the damage caused by the human falls problem. The above is also confirmed by the presence in the literature of several reviews dedicated to this specific topic \cite{mubashir2013survey, khan2017review, lapierre2017state, pannurat2014automatic, xu2018new, el2013fall}.
In fact, in the past few years, a variety of systems have been presented. One way to divide the methodologies for approaching the falls detection problem is based on the placement of the sensing devices \cite{mubashir2013survey}. The main categories are wearable, vision and environmental, with each category presenting advantages and disadvantages. Wearable systems do not suffer from ambient condition, but people may forget to wear them, and they are not operational during the charging time; thus, some people may consider them annoying. Furthermore, a device must be installed on each person to be monitored. An environmental sensor may be used to avoid this kind of problems, but with other limitations. Vision systems, although they are actually environmental sensors, deserve a dedicated category because of many systems proposed in the literature based on this type of sensors \cite{mubashir2013survey}. This category includes several types of sensors like, e.g., cameras for which the major limitations are field-of-view constraints, lighting condition, the positioning of multiple cameras and lack of privacy.
The ambient category includes several types of sensors. For example, radar doppler based systems used in \cite{wu2015radar} raise fewer privacy concerns, but they suffer from reflection and blind spots. In particular, for a data-driven system, another aspect that should not be underestimated is the need for a re-training when changing the environment to be monitored or even just some of its components such as the arrangement of furniture as happens in \cite{liu2008vision}.
All this implies that there is no optimal choice, which is instead, a compromise that depends on the type of environment that is monitored as well as on personal sensitivity of the subjects under monitoring.
Going into more detail, another significant distinction between falls detection systems can be made based on the type and amount of data used for the algorithm development \cite{khan2017review}. In fact, the problem can be approached either as supervised or unsupervised based on the availability of data in the hands of the researchers as well as their goals. 
Most state-of-the-art works tackle the problem under fully supervised conditions assuming they have enough data for falls. Almost all of these falls are simulated with professional mannequins \cite{werner2011fall, zigel2009method}  or by people with adequate protections \cite{li2012microphone, popescu2008acoustic} that however may not correctly emulate an actual fall. Although this approach leads to more accurate results, there is no guarantee that it will generalize well in real situations. 
Other researchers opt for approaches based on outlier/anomaly detection \cite{khan2015unsupervised, zhang2009detecting, popescu2009acoustic} because of the plentiful availability of data that can represent normal activity. However, it is challenging to define what ``normal activities'' are for such approaches, and the risk is to raise several false alarms. % come succede a noi con la ocsvm.
Perhaps the situation that most closely approximates reality is a hybrid between the previous ones, in which a large amount of data representing the normality are easily available, with just a few samples of real human fall and eventually some related synthetic or simulated data. In these situations, supervised approaches that suffer from strong data imbalance have to apply subsampling \cite{stone2015fall} or weighting \cite{khan2017review} techniques to mitigate this effect. Thus, the need to find an effective way to exploit the few available falls data is evident.

\section{State-Of-The-Art} 
\label{sec:soa}

Fall detection approaches can be divided based on their sensing technology, in particular if they employ wearable or ambient sensors. Several fall detection systems have been presented in
the literature, the majority of which are based on wearable accelerometers or
smart cameras \cite{mubashir2013survey, khan2017review, lapierre2017state, pannurat2014automatic, xu2018new, el2013fall}. 

\subsection{Wearable}
Regarding the first ones, the most common choice is to employ accelerometers. The algorithms proposed in \cite{Bourke2007} and \cite{Charlon2013} detect a fall by verifying if the acceleration signals exceed a certain threshold. In contrast, in \cite{Ozdemir2014} the authors implemented several machine learning techniques and studied their classification performance. For the experiments, a fall events dataset has been developed using six sensor units with three-axis accelerometers and worn by 14 persons who simulated falls from different angles. The best performing classifier has been the $k$-Nearest Neighbour classifier. \cite{Lustrek2015} employed radio tags worn on the user's chest, waist, and ankles, and an optional three-axial accelerometer worn on the chest. The algorithm performs a basic activity recognition, distinguishing from walking, standing, sitting, sitting on the ground, lying down, the process of sitting or lying down, the process of standing up and falling. The actual fall is detected combining the results of two classifiers, an SVM and a decision tree, and hand-crafted rules. The authors performed the experiments on a laboratory scenario and reported accuracies of 100\% combining radio tags and the accelerometer.

%\cite{lai2011detection}
\subsection{Environmental}
Differently from wearable sensors, the physical quantities captured by ambient sensors are more heterogeneous. Generally, fall detectors are based on vibration, video or acoustic sensors, sometimes in combination with presence detectors.  In \cite{alwan2006smart} the fall detector is based on a floor vibration sensor and the algorithm detects a fall when the vibration pattern matches the one of a human fall. The authors do not give further details on the algorithm and report 100\% sensitivity, and specificity on tests conducted on a dummy falls dataset. Yazar and colleagues \cite{Yazar2013} employ both passive infrared (PIR) sensors and floor vibration sensors. PIRs are employed to reduce false alarms, i.e., by detecting if a person is present in the region of interest. Single-tree complex wavelet transform features are extracted from the vibration signal and classified as fall or non-fall. In their dataset, the non-fall classes are represented by human (walking or running and sitting) or non-human activities (door slamming and a book falling). Three different classifiers have been compared: Euclidean distance, Mahalanobis distance and SVM, with the latter resulting in the most performing one, since it is able to classify human falls without errors regardless the employment of PIR sensors.

\subsubsection{Audio based system}
Regarding approaches based on audio signals, a common solution is to install several microphones in the building, usually on the ceiling or near the walls.
\paragraph{Single Microphone}
 Indeed, also single-microphone approaches exist but they are much less robust to environmental noise, thus resulting in poor performance. For example, in \cite{zhuang2009acoustic}, the authors employ a single far-field microphone and they model audio segments by means of perceptual linear predictive (PLP) coefficients and GMM supervectors. An SVM with a kernel based on the Kullback-Leibler divergence, then, classifies the segment as being a fall or noise. For this purpose, nine classes of noise have been considered. In the experiments, the algorithm achieves an F$_1$-Measure of 67\% in the classification task, and accuracy equal to 64\% in the detection task. 
 Cheffena \cite{cheffena2016fall} propose a supervised fall detection algorithm based on smartphone microphones. The falls were performed and recorded from different volunteers with a smartphone placed within 5\,m from them. This system may not work when the person is far or in a different room. The author has evaluated different types of features and supervised algorithms, achieving the best accuracy performance of about 98\% with spectrogram features as the input of an artificial neural network.
 Collado et al. \cite{collado2017machine} present a comparison with 7 binary supervised machine learning methods, using 10 standard audio features like the energy of the signal, zero-crossing, spectral centroid, etc. They assessed the performance on a dataset composed of falls performed by a stunt actor. The non-fall class was represented by a human conversation and television background. Due to the strong classes unbalance, they have sub-sampled the non-fall class, getting the same number of instances of the fall class. In this context, a Logistic Regression approach achieved the best results of 93.3\% in terms of F$_1$-measure.
 Differently, Irtaza et al. \cite{irtaza2017framework} show a Support Vector Machine approach trained on Acoustic-Local Ternary Patterns features. Similarly to \cite{collado2017machine}, the problem of an unbalanced dataset has been faced by under-sampling the non-fall class. In this case, the non-fall class is represented by human activity sounds and some object falling, while they have used human falls sounds recorded with the aid of human subjects.

\paragraph{Microphone Array}
The difficulty in using a single microphone drove the scientific community to employ multi-channel algorithms. In \cite{khan2015unsupervised} the authors present an unsupervised algorithm based on two microphones. The algorithm comprises a source separation and localization block to reduce the impact of background noise. Then, a One-Class Support Vector Machine is trained on MFCCs of non-fall events only. The SVM is then applied to distinguish ordinary sound events (i.e., sounds originating from normal activities) from unusual ones (i.e., falls sounds). The authors validated the algorithm using simulated falls of persons only in the presence of television that produced the interfering sound. The results, in terms of Area Under Curve, are 99.28\% without interference and 97.38\% with 75\% interference. The work by Li and colleagues \cite{li2012microphone} employs a circular microphone array to firstly determine the position of the sound source and then to enhance the signal by applying a beamformer. The height of the sound source is used as the first filter to discriminate falls from non-falls. If the sound originates from a source positioned on the ground, MFCC features are extracted and a $k$-Nearest Neighbour classifier is employed to detect persons' falls. The algorithm has been tested on a dataset composed of 120 simulated fall sounds and 120 non-fall sounds recorded in different acoustic conditions. In the presence of background noise and TV interference, the resulting AUC was equal to 0.989 (accuracy 95\%) on clean conditions and 0.932 at 10\,dB SNR (accuracy 89\%). 
Popescu et al. \cite{popescu2008acoustic} proposed a 2-stage threshold based method using a microphone array. The first step is to compute the energy of the acquired signal. Then if the value exceeds a threshold, a sound localization is performed to remove possible false alarms. In the end, if the sound was detected from above a specific height, the alarm is removed. The human falls for testing were performed by only one stunt actor falling on a mattress.

\paragraph{Combined Solutions}
An approach to improve the performance of fall detection systems is to combine the information coming from different sensors. The approach proposed by Zigel \textit{et al.} \cite{zigel2009method} is based on a combination of sound and vibration sensors attached to the floor with an adhesive tape. The algorithm employs energy features extracted from the vibration signal to detect the fall event. Then, the event is classified as fall or non-fall with naive Bayes classifier employing features from both the vibration and sound signals. The experiments were conducted on a dataset containing falls of the ``Rescue Randy'' human mimicking doll and four objects, and the resulting sensitivity and specificity were respectively 97.5\% and 98.6\%. \cite{Liu2014} fuse the information coming from a Doppler sensor and motion sensors and classify the falls with an SVM. The authors report an AUC equal to 0.98 with Doppler sensor only, and a further reduction of false alarms by 63\% employing motion sensors information. Motion, sound and video signals are employed in \cite{Doukas2011}. Signals are captured both from environment sensors and from body sensors. A fall is detected by analyzing sounds and motion information, while visual and motion behavior indicates the severity of the fall. The work by Toreyin and colleagues \cite{Toreyin2008} combines PIRs, microphones and vibration sensors. Signals are processed to extract features in the wavelet domain, and HMM classifier is then employed to detect falls. The authors showed the using PIR signals 100\% accuracy could be obtained.
In \cite{er2018non} a solution based on wearable accelerometers and microphones has been proposed. The solution employs empirical rules to detect a fall and validate it combining the sound pressure information utilizing fuzzy logic. The fall instances for training have been performed by volunteer falling on a soft rubber foam mat to cushion the impact of falls.

\section{Motivations and Contributions}

Generally speaking, the ``analytical methods'' distinguish between fall and non-fall events by applying a threshold directly on the acquired signals or on the features sequences extracted from them \cite{noury2007fall}.
These methods are generally built exploiting some a priori knowledge to operate in a specific scenario and needs manual tuning of the hyperparameters of the algorithm. For these reasons, the ``analytical methods'' can hardly perform when the operating conditions and the subjects are variable. In ``machine learning'' methods, the algorithm learns from the data how to discriminate falls from non-falls \cite{noury2007fall}. Between them can be distinguished ``supervised'' and  ``unsupervised'' approaches. The first requires a labeled dataset for training the classifier, while the latter builds a normality model considering only the non-fall events. Regardless of the used approach, machine learning tasks require that the inputs be mathematically and computationally convenient to process, so researchers have traditionally relied on a two-stage strategy: some features are extracted from the raw signals of the dataset and are then used as input for the successive tasks. The choice and design of the appropriate features requires considerable expertise about the problem and constitutes a significant engineering effort.
%This work is aimed at the presentation of different computational audio processing systems for fall detection. The approaches described in each chapter follows a data availability perspective, that means the systems that presented will approach the problem by considering increasingly complex and realistic scenarios starting from different knowledge conditions. 
The main contribution is to demonstrate that the audio human fall detection is a reliable solution and not only the mainstream systems based on vision or wearable sensors can be used for this kind of problem. A particular acoustic sensor specially designed for the fall detection task is proposed and evaluated. Moreover, the dataset used to assess all the proposed methods has been created by the same authors and made available by the scientific community. The authors aim to provide a complete dataset to the scientific community, that other researchers can use in order to compare the performances of their proposed systems in the audio field concerning the detection of human falls. 
In this work, different applications of computational audio processing based on machine learning techniques for ambient intelligence are analyzed. Particular attention was given to the knowledge condition each proposed approach. In fact, the presented works start from a total knowledge of the data describing first the supervised methods dedicated to the falls detection. Because of the difficulty in recovering examples of human fall for algorithm training, this is primarily just a case study. Subsequently, methods that operate in the opposite condition are described, that is, without the a priori knowledge of signals related to the human fall. This would be the ideal condition, but that does not present very high reliability in terms of false alarms rate. Finally, the problem is dealt with from a more realistic point of view, in which only a small portion of data related to the human fall is available, while a vast knowledge of what is not human fall can be accessed.

The outline of the dissertation is the following.
In \secref{sec:fds} has been introduced the human fall classification task with an updated followed by a state-of-the-art mainly focused on the audio based approaches. 
\chref{ch:backg} gives an overview of the theoretical background of the data-driven techniques used during the development of the presented systems. The \chref{ch:dataset} described the dataset made by the authors, used for the assessment of the systems. \chref{ch:supervised_approaches} presents the supervised approaches aimed to evaluate both the created dataset and the innovative proposed sensor.
The unsupervised systems are described in \chref{ch:unsupervised_approaches} where no human fall data has been used to train the algorithms.
In \chref{ch:weakley_supervised} approaches that operate in more realistic conditions are described, where additional information is provided by the user or available for the target class.

