% !TeX spellcheck = it_IT
\documentclass{beamer}

\usepackage[latin1]{inputenc}
\usepackage[tight]{subfigure}
\usepackage{graphicx}
\usepackage{multirow}
\usepackage{threeparttable}
\usepackage{booktabs}

\graphicspath {{imgs/}}
\usepackage{tikz}
\usetikzlibrary{calc,shapes,arrows,chains,shadows,arrows,fit,positioning,backgrounds,spy}

\usetheme[pageofpages=of,% String used between the current page and the
% total page count.
bullet=circle,% Use circles instead of squares for bullets.
titleline=true,% Show a line below the frame title.
alternativetitlepage=true,% Use the fancy title page.
titlepagelogo=logo_univpm.png,% Logo for the first page.
%watermark=brando1,% Watermark used in every page.
%watermarkheight=20px,% Height of the watermark.
%watermarkheightmult=5,% The watermark image is 4 times bigger
% than watermarkheight.
]{Torino}

\setbeamertemplate{background}{
	\tikz[overlay,remember picture] 
	\node[at=(current page.north east),anchor=north east,inner sep=15pt] {\includegraphics[height=1cm, keepaspectratio]{logo_univpm_scritta.png}};
}

\author{\textbf{Studente:}Diego Droghini}
\title{Scuola di Dottorato in Ingegneria dell'Informazione}
\subtitle{XVII Ciclo n.s., 3° anno di corso (2017/2018)}
\institute{Università Politecnica delle Marche\\ \textbf{Progetto Eureka}}
\date{}

\definecolor{darkgray}{RGB}{50,50,50}

\setbeamercolor{section in toc}{fg=black}
\setbeamercolor{subsection in toc}{fg=darkgray}
\setbeamerfont{subsection in toc}{size=\small}
\setbeamertemplate{section in toc}[ball unnumbered] %[sections numbered]
%\setbeamertemplate{subsection in toc}[subsections numbered]


\begin{document}

\begin{frame}[t,plain]
\titlepage
\end{frame}

\begin{frame}[t]{PhD Thesis}
	\vspace{1.5cm}
	\centering
	\huge
	\textbf{Ambient Intelligence:
\\
	Computational Audio Processing
	For Human Fall Detection}
\end{frame}

%\begin{frame}{Overview}
%	\tableofcontents
%	% You might wish to add the option [pausesections]
%\end{frame}
\begin{frame}
	\frametitle{Outline}
	\begin{columns}[t]
		\begin{column}{.5\textwidth}
			\tableofcontents[sections={1-4}]
		\end{column}
		\begin{column}{.5\textwidth}
			\tableofcontents[sections={5-8}]
		\end{column}
	\end{columns}
\end{frame}

\AtBeginSubsection[]{%
	\begin{frame}<beamer>{Index}
		\tableofcontents[currentsection,currentsubsection]
	\end{frame}
}
\AtBeginSubsection[]{%
	\begin{frame}<beamer>{Index}
			\begin{columns}[t]
				\begin{column}{.5\textwidth}
					\tableofcontents[sections={1-4}, currentsection,currentsubsection]
				\end{column}
				\begin{column}{.5\textwidth}
					\tableofcontents[sections={5-8},currentsection,currentsubsection]
				\end{column}
			\end{columns}
		\end{frame}

}



\section{Introduction}		
\begin{frame}{Human fall: a real problem for society}
	%			"And why do we fall, Bruce? So we can learn to pick ourselves up" cit. Batman Begins
	\begin{block}{"And why do we fall, Bruce? So we can learn to pick ourselves up" cit. Batman Begins}
		
		\begin{itemize}
			\item 62\% of injury-related hospitalizations for the
			people over 65 years are the result of a fall \cite{gurley1996persons}
			\item main cause of death due to accidents for people
			over 65 \cite{mubashir2013survey}
			\item can lead to psychophysical repercussions on people \cite{abbate2010monitoring}
		\end{itemize}
	\end{block}
	\begin{block}{What can be done whit FCS}
		
		\begin{itemize}
			\item Monitoring of the elderly or people who live alone
			\item Assistance time reduction
		\end{itemize}
		
	\end{block}
	
\end{frame}
\begin{frame}{Fall Classification System Challenge \cite{khan2017review}}
	
	\begin{itemize}
		\item Try to collect sufficient human fall data 
		\begin{itemize}
			\item Supervised methods (SVM): HF in training 
			
			\begin{itemize}
				\item difficulty in retrieving examples that
				represent human falls
			\end{itemize}	
		\end{itemize}
		\item Deal with no human fall data
		\begin{itemize}
			\item Novelty detection approach (OCSVM) 
			\begin{itemize}
				\item good description of "normality"
				
			\end{itemize}	
		\end{itemize}
	\end{itemize}
	
	
	\begin{minipage}[c]{0.48\textwidth}
		
		\begin{block}{Related Work}	
			\begin{itemize}
				\item Wearable
				\begin{itemize}
					\item Accelerometers
					\item Gyroscopes 	
				\end{itemize}
				\item Ambient 
				\begin{itemize}
					\item Vision System
					\item Audio microphone
					\item Radar doppler 	
				\end{itemize}				
			\end{itemize}
		\end{block}
		
	\end{minipage}
	\hfill%
	\begin{minipage}[c]{0.48\textwidth}
		
		\centering
		\hspace{0.8cm}\alert{Fall Event} \\
		\vspace{0.5cm}
		\hspace{0.8cm}\includegraphics[width=0.5\textwidth]{imgs/slip_and_fall}\\
		
	\end{minipage}%
\end{frame}


\begin{frame}[t]{Motivations and Contributions}
%	analytical methods distinguish between fall and nonfall events by applying a threshold directly on the acquired signals or on the
%	features sequences extracted from them.  These methods are generally built
%	exploiting some a priori knowledge to operate in a specific scenario and needs
%	manual tuning of the hyperparameters of the algorithm. For these reasons,
%	the ?analytical methods? can hardly perform when the operating conditions
%	and the subjects are variable. In ?machine learning? methods, the algorithm
%	learns from the data how to discriminate falls from non-falls.
%	The main contribution is to demonstrate that the audio human fall detection is a reliable
%	solution and not only the mainstream systems based on vision or wearable sensors can be used for this kind of problem. A particular acoustic sensor specially
%	designed for the fall detection task is proposed and evaluated. Moreover, the
%	dataset used to assess all the proposed methods has been created by the same
%	authors and made available by the scientific community
	
\end{frame}

\section{Dataset}
\subsection{FAS}
		\begin{frame}{Floor Acoustic Sensor\cite{Principi2016a}}%\footnotemark}
	
	\begin{minipage}[c]{0.5\textwidth}
		\begin{enumerate}
			\item The outer container
			\item The inner container
			\item The microphone slot
			\item The membrane touching the floor
		\end{enumerate}
	\end{minipage}%
	\hfill%
	\begin{minipage}[c]{0.5\textwidth}
		\centering
		
		\includegraphics[width=1\textwidth]{imgs/AcousticSensor}\\
		
	\end{minipage} 
	\begin{block}{Advantage}
		\begin{itemize}
			\item Easily integrated into the environment
			\item More sensitive to signals related to falls
		\end{itemize}
	\end{block}
	%\vspace{0.5cm}
	\begin{columns}[c]
		\begin{column}[c]{0.5\textwidth}
			\hspace{1.5cm}\vspace{0.2cm}
			3D printed prototype 	
		\end{column}
		\begin{column}[c]{0.5\textwidth}
			\hspace{1cm}\vspace{.2cm}				
			\includegraphics[width=0.6\textwidth]{imgs/FAS_front_little.jpg}
		\end{column}
	\end{columns}
	
	%\footnotetext[1]{Patent AN2013A000056, 18/03/2013, Paolo Olivetti}
\end{frame}
	
	

\subsection{A3FALL Dataset}
\begin{frame}[t]{The fall events dataset: A3Fall}
	
motivazione: mancaza di dataset audio adeguati
descrizione generale: descrizione 3 stanze 
\end{frame}

\begin{frame}[t]{The recording setup}
	strumentazione: microfoni (fas e aerei + randy + sceda audio + marche microfoni)
\end{frame}

\begin{frame}[t]{Description}
	aggingere qualcosa sulla sinistra
\tiny
\begin{table}[t]
%	\caption{Composition of the A3Fall-v2.0 dataset.}
	\label{tab:numDataset}
	\begin{center}
		\begin{tabular}[t]{c|ccc}
			
			\hline
			\textbf{Class} & \textbf{R0} & \textbf{R1} & \textbf{R2} \\ %\cline{2-5} 
			%& \hspace{8pt}Clean\hspace{8pt}  & \hspace{6pt}Clean\hspace{6pt}   \\ 
			\hline
			&\multicolumn{3}{c}{Nr. of occurrences}\\
			Basket      			& 64    &   40 	&   40    	\\
			Fork        			& 64    &   40 	&   40     	\\
			Ball       				& 64    &   40	&   40    	\\
			Book        			& 64    &   40	&   40    	\\
			Bag         			& 64    &   30 	&   40    	\\
			Chair       			& 96    &   40 	&   40    	\\
			Table       			& 0   	&   40 	&   40    	\\
			Guitar Slide       		& 0   	&   40 	&   40    	\\
			Nipper       			& 0    	&   40 	&   40    	\\
			Keys       				& 0    	&   40 	&   40    	\\
			Hook       				& 0    	&   40 	&   40    	\\
			Coat Hook       		& 0    	&   40 	&   40    	\\
			$\,$ Manikin Doll $\,$ 	& 44    &   0 	&   0    	\\
			$\,$ Human Fall $\,$ 	& 0    	&   40 	&   40    	\\
			\hline
			&\multicolumn{3}{c}{Total length (s)}\\			
			%			Human Activity  		& 1135  &   3050&   580   	\\
			%			Music					& 1395  &	4330&   3345  	\\
			%			Television				& 0   	&	1675&   1625  	\\
			Background  			& 2530  &   9055&   5550   	\\
			\hline
		\end{tabular}
	\end{center}
\end{table}

\end{frame}
\begin{frame}[t]{Signal analysis}
	confronto mel channel e SNR tra fas e aereal
	
\end{frame}
\section{Supervised Approaches}
%\subsection{Multi-class SVM}
%\subsection{Binary SVM}
\begin{frame}[t]{Supervised Approaches}
	 unire multi e binary SVM 
	
\end{frame}

\section{Unsupervised Approach}
\subsection{OCSVM}
\subsection{End-To-End CNN-AE}
\section{Weakly-supervised Approach}
\subsection{OCSVM + Template Matching User-Aided}
\subsection{Few-shot Siamese Neural Networks}
\subsection{OneShot Siamese Autoencoders}	
\section{Other Contributions}

\begin{frame}{End-to-End Unsupervised Network for Audio Timbre Transfer}

\end{frame}
\section{Conclusions}
\begin{frame}{Conclusions}
	
\end{frame}

\begin{frame}[t]{Conferences and Workshop}

\begin{itemize}
\item \textbf{WIRN 2016}: 26th Italian Workshop on Neural Networks, May 18-20 2016, Vietri sul Mare, Salerno, Italy \hfill\textit{\scriptsize[1 oral presentation]}	

\item \textbf{EUSIPCO 2017}: 25th European Signal Processing Conference, 28 Ago.-2 Sept. 2017, Kos Island, Greece \textit{\scriptsize[1 oral presentation]}	

\item \textbf{WIRN 2018}: 28th Italian Workshop on Neural Networks, 13-15 June 2018, Vietri sul Mare, Salerno, Italy \hfill\textit{\scriptsize[1 oral presentation]}	

\item \textbf{EUSIPCO 2018}: 28th edition of the European Signal Processing Conference, Sept. 3-7 2018, Rome, Italy \hfill\textit{\scriptsize[1 poster]}	
\end{itemize}

\small
In addition:
\begin{itemize}
\item Speaker: ``Le nuove applicazioni dell'Intelligenza Artificiale in ambito musicale'', workshop at \textbf{Acusmatiq XII} - international festival of electronic, electro-acoustic and experimental music, 28 - 30 July 2017, Ancona, Italy 
\end{itemize}
\end{frame}



\begin{frame}[t]{Training Activity} 
\begin{itemize}
	\item\textbf{Courses}:
	\begin{itemize}
		\item ``Progettare la ricerca: i progetti europei'', Prof. Nicola Paone
		\item ``Economia e Management del Trasferimento Tecnologico'', Prof. Donato Iacobucci
	\end{itemize}
	\item \textbf{Seminars}:
	\begin{itemize}
	\item ``Automated Prominent Nucleoli Detection in Cancer Cells'', Dr. Hwee Kuan Lee
	\item ``Tecniche di Elaborazione Numerica dei Segnali Applicata alla Sintesi della Canna d'Organo'', Ing. Carlo Zinato
	\item ``Robustness Analysis of Binaural Loudspeaker Reproduction'', Prof. Risheng Xia - Feb. 21 2017
	\item ``From signal representations to musical creation: a geometric approach'', Dott. Carmine Cella - Mar. 16 2017
	\item ``Tecnologie Elettroniche nei Centri Dati di Google'', Dott. Anthony Tonizzo - May 17 2017
	\end{itemize}
\end{itemize}
\end{frame}


\begin{frame}[t]{Training Activity} 

\textbf{Other}:

\begin{itemize}
	\item Corso di Perfezionamento post laurea in \textit{Computer Music Production} organized by \textit{UnivPm } - \textbf{Awarded Certificate}

	\vspace{2mm}

	\item Integrative activity organized by the ``Contamination LAB'' concerning self-entrepreneurship - \textbf{Best Pitch Winner} (Team)
	
	\vspace{2mm}
	
	\item Reviewer for international journals (IEEE Transactions on Emerging Topics in Computational Intelligence, Information Processing in Agriculture) and international conferences (WIRN2016, IJCNN 2017, IJCNN 2018, ICONIP 2018).	
	
	
\end{itemize}

\end{frame}

\section{References}
\begin{frame}[allowframebreaks]
	\scriptsize
	\frametitle{References} 
	\nocite{*} 
	\bibliographystyle{IEEEbib} 
	\bibliography{mybib} 
\end{frame}

\section{Elenco Pubblicazioni}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[allowframebreaks]
\scriptsize
\frametitle{Publications List} 
\vspace{-4mm}
\textbf{International Journal}: \hfill \textit{\scriptsize[3 articles, 2 first author]}
\begin{thebibliography}{9}
\bibitem{marchideep}[1]
E.~Marchi, F.~Vesperini, S.~Squartini, and B.~Schuller,
\newblock ``Deep recurrent neural network-based autoencoders for acoustic novelty detection,'' 
\newblock {\em Computational Intelligence and Neuroscience}, 2016.

\bibitem{vesperini2017speaker}[2]
F.~Vesperini, P.~Vecchiotti, E.~Principi, S.~Squartini, and F.~Piazza,
\newblock ``Localizing speakers in multiple rooms by using deep neural
networks,'' \newblock {\em Computer Speech and Language}, 2017.
\end{thebibliography}
\vspace{2mm}
\textbf{International Journal (submitted)}: \hfill \textit{\scriptsize[1 article, 1 first author]}

\begin{thebibliography}{9}
\bibitem{vesperini2018polyphonic}[1]
F.~Vesperini, L.~Gabrielli, E.~Principi, and S.~Squartini,
\newblock ``Polyphonic sound event detection by using capsule neural
networks,''
\newblock {\em Journal of Selected Topics in Signal Processing}, 2018, submitted.
\end{thebibliography}

\vspace{4mm}

\textbf{International Conference}: \hfill \textit{\scriptsize[14 articles, 5 first author]}
\begin{thebibliography}{9}
\bibitem{Marchi15-ANA}[1]
E.~Marchi, F.~Vesperini, F.~Eyben, S.~Squartini, and B.~Schuller,
\newblock ``{A Novel Approach for Automatic Acoustic Novelty Detection Using a Denoising Autoencoder with Bidirectional LSTM Neural Networks},''
\newblock in {\em Proc. of ICASSP}, Brisbane, Australia, 19-24 Apr. 2015, IEEE.

\bibitem{Marchi15-NPW}[2]
E.~Marchi, F.~Vesperini, F.~Weninger, F.~Eyben, S.~Squartini, and B.~Schuller,
\newblock ``{Non-Linear Prediction with LSTM Recurrent Neural Networks for Acoustic Novelty Detection},'' \newblock in {\em Proc. of IJCNN}, Killarney, Ireland, 12-16 Jul. 2015, IEEE.

\bibitem{ijcnn2016-vad}[3]
F.~Vesperini, P.~Vecchiotti, E.~Principi, S.~Squartini, and F.~Piazza,
\newblock ``Deep neural networks for multi-room voice activity detection: Advancements and comparative evaluation,''
\newblock in {\em Proc. of IJCNN}, Vancouver, Canada, 24-29 Jul. 2016, IEEE, pp. 3391--3398.

\bibitem{gasparini2016combining}[4]
M.~Gasparini, F.~Vesperini, S.~Cecchi, S.~Squartini, F.~Piazza, and R.~Toppi,
\newblock ``Combining evolution strategies and neural network procedures for compression driver design,'' \newblock in {\em Proc. of IJCNN}, Vancouver, Canada, 24-29 Jul. 2016, IEEE,
pp. 3385--3390.

\bibitem{vecchiotti2018convolutional}[5]
P.~Vecchiotti, F.~Vesperini, E.~Principi, S.~Squartini, and F.~Piazza,
\newblock ``Convolutional neural networks with 3-{D} kernels for voice activity detection in a multiroom environment,'' 
\newblock in {\em Multidisciplinary Approaches to Neural Computing}, pp. 161--170. Springer, 2018.

\bibitem{mlsp2016-sloc}[6]
F.~Vesperini, P.~Vecchiotti, E.~Principi, S.~Squartini, and F.~Piazza,
\newblock ``A neural network based algorithm for speaker localization in a multi-room environment,''
\newblock in {\em Machine Learning for Signal Processing (MLSP), 2016 IEEE 26th International Workshop on}. IEEE, 2016, pp. 1--6.

\bibitem{principi2017acoustic}[7]
E.~Principi, F.~Vesperini, S.~Squartini, and F.~Piazza,
\newblock ``Acoustic novelty detection with adversarial autoencoders,''
\newblock in {\em Proc. of IJCNN}, Anchorage, Alaska, 14-19 May 2017, IEEE, pp.
3324--3330.

\bibitem{valenti2017sound}[8]
M.~Valenti, D.~Tonelli, F.~Vesperini, E.~Principi, and S.~Squartini,
\newblock ``A neural network approach for sound event detection in real life audio,''
\newblock in {\em Proc. of EUSIPCO}, Kos, Greece, Sept. 2017, IEEE.

\bibitem{gabrielli2018deep}[9]
L.~Gabrielli, C.~E. Cella, F.~Vesperini, D.~Droghini, E.~Principi, and S.~Squartini,
\newblock ``Deep learning for timbre modification and transfer: An evaluation study,''
\newblock in {\em Proc. of 144th AES}, Milan, Italy, 24-26 May 2018, Audio
Engineering Society.

\bibitem{ambrosini2018deep}[10]
L.~Ambrosini, L.~Gabrielli, F.~Vesperini, S.~Squartini, and L.~Cattani,
\newblock ``Deep neural networks for road surface roughness classification from acoustic signals,''
\newblock in {\em Proc. of 144th AES}, Milan, Italy, 24-26 May 2018, Audio
Engineering Society.

\bibitem{vesperini2018snoring}[11]
F.~Vesperini, A.~Galli, L.~Gabrielli, E.~Principi, and S.~Squartini,
\newblock ``Snore sounds excitation localization by using scattering transform and deep neural networks,''
\newblock in {\em Proc. of IJCNN}, Rio de Janeiro, Brasil, 8-13 Jul. 2018, IEEE.

\bibitem{vesperini2018hierarchic}[12]
F.~Vesperini, D.~Droghini, E.~Principi, L.~Gabrielli, and S.~Squartini,
\newblock ``Hierarchic {C}onv{N}ets framework for rare sound event detection,''
\newblock in {\em Proc. of EUSIPCO}. IEEE, Sept. 3-7 2018.

\bibitem{vesperini2018wirn}[13]
F.~Vesperini, L.~Romeo, E.~Principi, A.~Monteri\`{u}, and S.~Squartini,
\newblock ``Convolutional recurrent neural networks and acoustic data augmentation for snore detection,''
\newblock in {\em Proc. of WIRN}, Vietri sul Mare, Italy, 13-15 Jun. 2018.

\bibitem{Droghini2018}[14]
D.~Droghini, F.~Vesperini, E.~Principi, S.~Squartini, and F.~Piazza,
\newblock ``Few-shot siamese neural networks employing audio features for human-fall detection,''
\newblock in {\em Proc. of The International Conference on Pattern Recognition and Artificial Intelligence}, Union, NJ, USA, Aug. 15-17 2018.
\end{thebibliography}

\textbf{Others}:
\begin{thebibliography}{9}

\bibitem{vesperinihierarchic}
F.~Vesperini, D.~Droghini, D.~Ferretti, E.~Principi, L.~Gabrielli, S.~Squartini, and F.~Piazza,
\newblock ``A hierarchic multi-scaled approach for rare sound event detection,''
\newblock Ancona, Italy, 2017, {DCASE} {T}ech. {R}eport. {C}opyright-free.

\bibitem{vesperini2018capsule}
F.~Vesperini, L.~Gabrielli, E.~Principi, and S.~Squartini,
\newblock ``A capsule neural networks based approach for bird audio detection,''
\newblock Ancona, Italy, 2018, {DCASE} {T}ech. {R}eport. {C}opyright-free.

\bibitem{gabrielli2018rima}
L.~Gabrielli, F.~Vesperini, D.~Droghini, and S.~Squartini,
\newblock ``Rima {G}lottidis: Experimenting generative raw audio synthesis for a sound installation,''
\newblock in {\em XXII Colloquium of Musical Informatics}, Udine, Italy, 20-23 Nov. 2018.
\end{thebibliography}
\end{frame}

\end{document}